{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Preprocessing\n",
    "\n",
    "#### Initialise Spark Session and Load Data from HDFS into Spark DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark_local = SparkSession.builder.appName(\"MovieLensAnalysisLocal\").getOrCreate()\n",
    "\n",
    "movies_df = spark_local.read.csv(\"hdfs://namenode:9000/movies.csv\", header=True, inferSchema=True)\n",
    "ratings_df = spark_local.read.csv(\"hdfs://namenode:9000/ratings.csv\", header=True, inferSchema=True)\n",
    "tags_df = spark_local.read.csv(\"hdfs://namenode:9000/tags.csv\", header=True, inferSchema=True)\n",
    "links_df = spark_local.read.csv(\"hdfs://namenode:9000/links.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore Data Schema and Sample Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.printSchema()\n",
    "movies_df.show(5)\n",
    "\n",
    "ratings_df.printSchema()\n",
    "ratings_df.show(5)\n",
    "\n",
    "tags_df.printSchema()\n",
    "tags_df.show(5)\n",
    "\n",
    "links_df.printSchema()\n",
    "links_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle Missing Values and Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = movies_df.na.drop()\n",
    "ratings_df = ratings_df.na.drop()\n",
    "tags_df = tags_df.na.drop()\n",
    "links_df = links_df.na.drop()\n",
    "\n",
    "movies_df = movies_df.dropDuplicates()\n",
    "ratings_df = ratings_df.dropDuplicates()\n",
    "tags_df = tags_df.dropDuplicates()\n",
    "links_df = links_df.dropDuplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split Genres into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "\n",
    "movies_df = movies_df.withColumn(\"genres_array\", split(movies_df[\"genres\"], \"\\\\|\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRUD Operations\n",
    "#### Create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "from pyspark.sql.functions import split\n",
    "\n",
    "movies_df_copy = movies_df\n",
    "\n",
    "\n",
    "new_movie = Row(movieId=999999, title=\"New Movie (2024)\", genres=\"Sci-Fi|Drama\")\n",
    "\n",
    "\n",
    "new_movie_df = spark_local.createDataFrame([new_movie])\n",
    "new_movie_df = new_movie_df.withColumn(\"genres_array\", split(new_movie_df[\"genres\"], \"\\\\|\"))\n",
    "movies_df_copy = movies_df_copy.select(\"movieId\", \"title\", \"genres\").withColumn(\"genres_array\", split(movies_df_copy[\"genres\"], \"\\\\|\"))\n",
    "movies_df_copy = movies_df_copy.union(new_movie_df.select(\"movieId\", \"title\", \"genres\", \"genres_array\"))\n",
    "movies_df_copy.filter(movies_df_copy.movieId == 999999).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract, col\n",
    "\n",
    "# filter movies by sci-fi genre\n",
    "sci_fi_movies = movies_df_copy.filter(\n",
    "    (movies_df.genres.contains(\"Sci-Fi\"))\n",
    ")\n",
    "\n",
    "# select and display the top 5 movies\n",
    "sci_fi_movies.select(\"title\", \"genres\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "\n",
    "# update the genres for the movie with movieId = 999999 (one I created ealier)\n",
    "movies_df_copy = movies_df_copy.withColumn(\n",
    "    \"genres\",\n",
    "    when(movies_df_copy.movieId == 999999, \"Thriller|Action\").otherwise(movies_df_copy.genres)\n",
    ")\n",
    "\n",
    "# Verify the update\n",
    "movies_df_copy.filter(movies_df_copy.movieId == 999999).select(\"movieId\", \"title\", \"genres\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import regexp_extract\n",
    "\n",
    "movies_df_copy = movies_df_copy.withColumn(\"year\", regexp_extract(movies_df_copy[\"title\"], r\"\\((\\d{4})\\)\", 1))\n",
    "movies_df_copy = movies_df_copy.filter(movies_df_copy.year != \"2020\")\n",
    "\n",
    "movies_df_copy.write.mode(\"overwrite\").parquet(\"hdfs://namenode:9000/movies_df_copy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now use master for complex SQL queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_master = SparkSession.builder \\\n",
    "        .appName(\"MovieLensAnalysis\") \\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "movies_df = spark_master.read.csv(\"hdfs://namenode:9000/movies.csv\", header=True, inferSchema=True)\n",
    "ratings_df = spark_master.read.csv(\"hdfs://namenode:9000/ratings.csv\", header=True, inferSchema=True)\n",
    "tags_df = spark_master.read.csv(\"hdfs://namenode:9000/tags.csv\", header=True, inferSchema=True)\n",
    "links_df = spark_master.read.csv(\"hdfs://namenode:9000/links.csv\", header=True, inferSchema=True)\n",
    "\n",
    "movies_df = movies_df.na.drop()\n",
    "ratings_df = ratings_df.na.drop()\n",
    "tags_df = tags_df.na.drop()\n",
    "links_df = links_df.na.drop()\n",
    "movies_df = movies_df.dropDuplicates()\n",
    "ratings_df = ratings_df.dropDuplicates()\n",
    "tags_df = tags_df.dropDuplicates()\n",
    "links_df = links_df.dropDuplicates()\n",
    "\n",
    "movies_df = movies_df.withColumn(\"genres_array\", split(movies_df[\"genres\"], \"\\\\|\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complex Big Data Queries Using Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df.createOrReplaceTempView(\"movies\")\n",
    "ratings_df.createOrReplaceTempView(\"ratings\")\n",
    "tags_df.createOrReplaceTempView(\"tags\")\n",
    "links_df.createOrReplaceTempView(\"links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 1: Top Tags Associated with High-Rated Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "top_tags = spark_master.sql(\"\"\"\n",
    "SELECT\n",
    "    t.tag,\n",
    "    COUNT(*) AS tag_count\n",
    "FROM tags t\n",
    "JOIN (\n",
    "    SELECT\n",
    "        movieId,\n",
    "        AVG(rating) AS avg_rating\n",
    "    FROM ratings\n",
    "    GROUP BY movieId\n",
    "    HAVING avg_rating > 4.5\n",
    ") high_rated_movies ON t.movieId = high_rated_movies.movieId\n",
    "GROUP BY t.tag\n",
    "ORDER BY tag_count DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "top_tags_pd = top_tags.toPandas()\n",
    "plt.barh(top_tags_pd['tag'], top_tags_pd['tag_count'])\n",
    "plt.xlabel('Tag Count')\n",
    "plt.ylabel('Tag')\n",
    "plt.title('Top Tags for High-Rated Movies')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 2: Top Genres by Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_genres = spark_master.sql(\"\"\"\n",
    "SELECT\n",
    "    genre,\n",
    "    AVG(avg_rating) AS avg_genre_rating\n",
    "FROM (\n",
    "    SELECT\n",
    "        genre,\n",
    "        AVG(r.rating) AS avg_rating\n",
    "    FROM movies m\n",
    "    JOIN ratings r ON m.movieId = r.movieId\n",
    "    LATERAL VIEW explode(m.genres_array) AS genre\n",
    "    GROUP BY genre\n",
    ") tmp\n",
    "GROUP BY genre\n",
    "ORDER BY avg_genre_rating DESC\n",
    "LIMIT 5\n",
    "\"\"\")\n",
    "\n",
    "top_genres_pd = top_genres.toPandas()\n",
    "plt.bar(top_genres_pd['genre'], top_genres_pd['avg_genre_rating'])\n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Top 5 Genres by Average Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Query 3: Correlation Between Movie Popularity and Average Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "popularity_vs_rating = spark_master.sql(\"\"\"\n",
    "SELECT\n",
    "    m.movieId,\n",
    "    m.title,\n",
    "    COUNT(r.rating) AS num_ratings,\n",
    "    AVG(r.rating) AS avg_rating\n",
    "FROM movies m\n",
    "JOIN ratings r ON m.movieId = r.movieId\n",
    "GROUP BY m.movieId, m.title\n",
    "HAVING COUNT(r.rating) > 100\n",
    "ORDER BY num_ratings DESC\n",
    "\"\"\")\n",
    "\n",
    "popularity_vs_rating_pd = popularity_vs_rating.toPandas()\n",
    "plt.scatter(popularity_vs_rating_pd['num_ratings'], popularity_vs_rating_pd['avg_rating'])\n",
    "plt.xlabel('Number of Ratings')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.title('Movie Popularity vs. Average Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query 4: Most Active Users and the Movies They Rated the Most"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_active_users_avg = spark_master.sql(\"\"\"\n",
    "SELECT\n",
    "    r.userId,\n",
    "    COUNT(r.movieId) AS movie_count,\n",
    "    AVG(r.rating) AS avg_rating\n",
    "FROM ratings r\n",
    "JOIN movies m ON r.movieId = m.movieId\n",
    "GROUP BY r.userId\n",
    "ORDER BY movie_count DESC\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "most_active_users_avg_pd = most_active_users_avg.toPandas()\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(most_active_users_avg_pd['userId'].astype(str), \n",
    "         most_active_users_avg_pd['avg_rating'])\n",
    "plt.xlabel('Average Rating')\n",
    "plt.ylabel('User ID')\n",
    "plt.title('Average Rating Given by Top 10 Most Active Users')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
